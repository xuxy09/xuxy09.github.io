<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiangyu Xu</title>

  <meta name="author" content="Xiangyu Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:68%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Xiangyu Xu</name>
                  </p>
                  <p> I am a full Professor at <a href="http://en.xjtu.edu.cn">Xi'an Jiaotong University</a>. I work on
                    computer vision and machine learning.
                    <!--               </p> -->
                    <!--               <p> -->
                    <!--                 I've worked on <a href="https://arxiv.org/abs/2102.01579">RawSR</a>, <a href="https://arxiv.org/abs/1911.00627">QVI</a>, <a href="https://arxiv.org/abs/2103.06498">RSC-Net</a>, and <a href="https://arxiv.org/abs/2109.02563">Texformer</a>.  -->
                    I got my Bachelor degrees from <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> and
                    <a href="https://nsd.pku.edu.cn/">Peking University</a>.
                    I did my PhD at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> and my Postdoc at
                    <a href="https://www.ri.cmu.edu/">Carnegie Mellon University</a>.

                    <br>
                    <br>
                    I am looking for PhD, Master, and Undergraduate students and Postdocs to join my lab. Please drop me
                    an email if you are interested.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:xuxiangyu2014@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="data/bio.md">Bio</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=Ec5Biz4AAAAJ">Google Scholar</a> 
                    <!-- &nbsp/&nbsp -->
                    <!-- <a href="https://calendly.com/xiangyuxu/xiangyu-s-open-office-hour">Chat</a> -->
                    <!-- &nbsp/&nbsp -->
                    <!-- <a href="https://github.com/xuxy09">Github</a> -->
                  </p>

                </td>
                <td style="padding:2.5%;width:20%;max-width:40%">
                  <a href="images/profile_xxy.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile_xxy.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                  <li>
                    Invited as an Area Chair for ICCV 2025
                  </li>
                  &nbsp;
                  <li>
                    <a href="https://arxiv.org/abs/2404.07206">GoodDrag</a> accepted to ICLR 2025
                  </li>
                  &nbsp;
                  <li>
                    Invited as an Area Chair for CVPR 2025
                  </li>
                  &nbsp;
                  <li>
                    Invited as an SPC for AAAI 2025
                  </li>
                  &nbsp;
                  <li>
                    üì¢ Call for Papers! üì¢ <strong><font
                      color="black">TPAMI Special Issue</font></strong> on <a href="https://genai3d.github.io/">"Generative AI in 3D Vision"</a> 
                    <!-- Representative papers are <span class="highlight">highlighted</span>. -->
                  </li>
                  &nbsp;
                  <li>
                    Invited as an Area Chair for ICLR 2025
                  </li>
                  &nbsp;
                  <li>
                    <a href="https://arxiv.org/abs/2403.14376">InfNeRF</a> accepted to SIGGRAPH Asia 2024
                  </li>
                  &nbsp;
                  <li>
                    Invited as an Area Chair for NeurIPS 2024
                  </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Publications</heading>
                  <p>
                    I'm interested in computer vision, machine learning, and image processing. 
                    <!-- Representative papers are <span class="highlight">highlighted</span>. -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:1px;border-spacing:1px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- arxiv25 dualsplat -->
              <tr onmouseout="arxiv25dualsplat_stop()" onmouseover="arxiv25dualsplat_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    
                    <div class="two" id='arxiv25dualsplat_image'>
                      
                      <video  width=100% height=auto muted autoplay loop>
                        <source src="images/arxiv25dualsplat.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                      
                    </div>
                    <img src='images/arxiv25dualsplat_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function arxiv25dualsplat_start() {
                      document.getElementById('arxiv25dualsplat_image').style.opacity = "1";
                    }

                    function arxiv25dualsplat_stop() {
                      document.getElementById('arxiv25dualsplat_image').style.opacity = "0";
                    }
                    arxiv25dualsplat_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2506.03538">
                    <papertitle>Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting</papertitle>
                  </a>
                  <br>
                  Chengqi Li, Zhihao Shi, Yangdi Lu, Wenbo He, <strong>Xiangyu Xu</strong> 
                  <br>
                  <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2025 &nbsp
                  <font color="red"><strong>(Spotlight)</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/2506.03538">Paper</a>
                  <p>3DGS in the wild with dual consistency regularization</p>
                </td>
              </tr>

              <!-- TIT25 -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <img src='images/rate-distortion-perception.png' width="160">
                  </div>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2406.18008">
                    <papertitle>Rate-Distortion-Perception Theory for the Quadratic Wasserstein Space</papertitle>
                  </a>
                  <br>
                  Xiqiang Qu, Jun Chen, Lei Yu, and <strong>Xiangyu Xu</strong>
                  <br>
                  <em>IEEE Transactions on Information Theory (<strong>TIT</strong>)</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2406.18008">Paper</a>
                  <p>Rate-distortion-perception theory under Wasserstein-2 distance, with explicit Gaussian formulas and shared randomness</p>
                </td>
              </tr>

              <!-- icml25 -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <img src='images/icml25wmarkgpt.png' width="160">
                  </div>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://openreview.net/pdf?id=HjVhSL76GM">
                    <papertitle>WMarkGPT: Watermarked Image Understanding via Multi-Modal Large Language Models</papertitle>
                  </a>
                  <br>
                  Songbai Tan, Xuerui Qiu, Gang Xu, Linrui Xu, <strong>Xiangyu Xu</strong>, Huiping Zhuang, Ming Li, Fei Yu 
                  <br>
                  <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2025
                  <br>
                  <a href="https://openreview.net/pdf?id=HjVhSL76GM">Paper</a>
                  <p>Watermarked image understanding with VLM</p>
                </td>
              </tr>

              <!-- arxiv24 gooddrag -->
              <tr onmouseout="arxiv24gooddrag_stop()" onmouseover="arxiv24gooddrag_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='arxiv24gooddrag_image'>
                      <img src='images/arxiv24gooddrag_after.gif' width="160">
                    </div>
                    <img src='images/arxiv24gooddrag_before.jpeg' width="160">
                  </div>
                  <script type="text/javascript">
                    function arxiv24gooddrag_start() {
                      document.getElementById('arxiv24gooddrag_image').style.opacity = "1";
                    }

                    function arxiv24gooddrag_stop() {
                      document.getElementById('arxiv24gooddrag_image').style.opacity = "0";
                    }
                    arxiv24gooddrag_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2404.07206">
                    <papertitle>GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models</papertitle>
                  </a>
                  <br>
                  Zewei Zhang, Huan Liu, Jun Chen, <strong>Xiangyu Xu</strong> 
                  <br>
                  <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2404.07206">Paper</a>
                  |
                  <a href="https://gooddrag.github.io/">Project</a>
                  <p>A new framework for drag editing with diffusion models.</p>
                </td>
              </tr>

              <!-- arxiv24 infnerf -->
              <tr onmouseout="arxiv24infnerf_stop()" onmouseover="arxiv24infnerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <!-- <div class="two" id='arxiv24infnerf_image'>
                      <img src='images/arxiv24infnerf_after.mp4' width="160">
                    </div> -->
                    <div class="two" id='arxiv24infnerf_image'><video  width=100% height=100% muted autoplay loop>
                      <source src="images/arxiv24infnerf_after.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video></div>
                    <img src='images/arxiv24infnerf_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function arxiv24infnerf_start() {
                      document.getElementById('arxiv24infnerf_image').style.opacity = "1";
                    }

                    function arxiv24infnerf_stop() {
                      document.getElementById('arxiv24infnerf_image').style.opacity = "0";
                    }
                    arxiv24infnerf_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2403.14376">
                    <papertitle>InfNeRF: Towards Infinite Scale NeRF Rendering with O(log n) Space Complexity</papertitle>
                  </a>
                  <br>
                  Jiabin Liang, Lanqing Zhang, Zhuoran Zhao, <strong>Xiangyu Xu</strong> 
                  <br>
                  <em><strong>SIGGRAPH Asia</strong></em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2403.14376">Paper</a>
                  |
                  <a href="https://github.com/sail-sg/InfNeRF">Project</a>
                  <p>We combine Level of Detail (LoD) with NeRF.</p>
                </td>
              </tr>

              <!-- CVPR24 deblur -->
              <tr onmouseout="cvpr24deblur_stop()" onmouseover="cvpr24deblur_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='cvpr24deblur_image'>
                      <img src='images/cvpr24deblur_after.png' width="160">
                    </div>
                    <img src='images/cvpr24deblur_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cvpr24deblur_start() {
                      document.getElementById('cvpr24deblur_image').style.opacity = "1";
                    }

                    function cvpr24deblur_stop() {
                      document.getElementById('cvpr24deblur_image').style.opacity = "0";
                    }
                    cvpr24deblur_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="">
                    <papertitle>Motion-Adaptive Separable Collaborative Filters for Blind Motion Deblurring</papertitle>
                  </a>
                  <br>
                  Chengxu Liu, Xuan Wang, <strong>Xiangyu Xu</strong>, Ruhao Tian, Shuai Li, Xueming Qian, Ming-Hsuan Yang 
                  <br>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2404.13153">Paper</a>
                  <p>Learnable filters for image deblurring.</p>
                </td>
              </tr>

              <!-- TPAMI23 smpler -->
              <tr onmouseout="tpami23smpler_stop()" onmouseover="tpami23smpler_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='tpami23smpler_image'>
                      <img src='images/tpami23smpler_after.png' width="160">
                    </div>
                    <img src='images/tpami23smpler_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function tpami23smpler_start() {
                      document.getElementById('tpami23smpler_image').style.opacity = "1";
                    }

                    function tpami23smpler_stop() {
                      document.getElementById('tpami23smpler_image').style.opacity = "0";
                    }
                    tpami23smpler_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="">
                    <papertitle>SMPLer: Taming Transformers for Monocular 3D Human Shape and Pose Estimation</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Lijuan Liu, Shuicheng Yan
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2404.15276">Paper</a>
                  |
                  <a href="https://github.com/xuxy09/SMPLer">Project</a>
                  <p>We propose a very simple Transformer for 3D human shape and pose estimation from a single image, which achieves SOTA accuracy with high efficiency in parameter and computation.</p>
                </td>
              </tr>

              <!-- arXiv23 Instant3D -->
              <tr onmouseout="arxiv23instant3d_stop()" onmouseover="arxiv23instant3d_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                      <div class="two" id='arxiv23instant3d_image'><video  width=100% height=100% muted autoplay loop>
                        <source src="images/arxiv23instant3d_after.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                        </video></div>
                      <!-- <img src='images/arxiv23instant3d_after.mp4' width="160"> -->
                    <img src='images/arxiv23instant3d_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function arxiv23instant3d_start() {
                      document.getElementById('arxiv23instant3d_image').style.opacity = "1";
                    }

                    function arxiv23instant3d_stop() {
                      document.getElementById('arxiv23instant3d_image').style.opacity = "0";
                    }
                    arxiv23instant3d_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="http://arxiv.org/abs/2311.08403">
                    <papertitle>Instant3D: Instant Text-to-3D Generation</papertitle>
                  </a>
                  <br>
                  Ming Li, Pan Zhou, Jia-Wei Liu, Jussi Keppo, Min Lin, Shuicheng Yan, <strong>Xiangyu Xu<sup>&#x2709</sup></strong>
                  <br>
                  <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2024
                  <br>
                  <a href="http://arxiv.org/abs/2311.08403">Paper</a>
                  |
                  <a href="https://ming1993li.github.io/Instant3DProj/">Project</a>
                  <p>Text-to-3D generation without per-prompt training, taking only under a second.</p>
                </td>
              </tr>

              <!-- arXiv23 progressive -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                      <!-- <div class="two" id='arxiv23progressive_image'><video  width=100% height=100% muted autoplay loop>
                        <source src="images/arxiv23progressive_after.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                        </video></div> -->
                      <!-- <img src='images/arxiv23progressive_after.mp4' width="160"> -->
                    <img src='images/arxiv23progressive.png' width="160">
                  </div>
                  <!-- <script type="text/javascript">
                    function arxiv23progressive_start() {
                      document.getElementById('arxiv23progressive_image').style.opacity = "1";
                    }

                    function arxiv23progressive_stop() {
                      document.getElementById('arxiv23progressive_image').style.opacity = "0";
                    }
                    arxiv23progressive_stop()
                  </script> -->
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2309.14600">
                    <papertitle>Progressive Text-to-3D Generation for Automatic 3D Prototyping</papertitle>
                  </a>
                  <br>
                  Han Yi, Zhedong Zheng, <strong>Xiangyu Xu</strong>, Tat-seng Chua
                  <br>
                  <em>arXiv</em>, 2023
                  <br>
                  <a href="https://arxiv.org/abs/2309.14600">Paper</a>
                  |
                  <a href="https://github.com/Texaser/MTN">Project</a>
                  <p>A progressive strategy that learns text-to-3D in a coarse-to-fine manner</p>
                </td>
              </tr>

              <!-- NIPS23 NUMCC -->
              <tr onmouseout="nips23numcc_stop()" onmouseover="nips23numcc_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='nips23numcc_image'>
                      <img src='images/nips23numcc_after.gif' width="160">
                    </div>
                    <img src='images/nips23numcc_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function nips23numcc_start() {
                      document.getElementById('nips23numcc_image').style.opacity = "1";
                    }

                    function nips23numcc_stop() {
                      document.getElementById('nips23numcc_image').style.opacity = "0";
                    }
                    nips23numcc_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2307.09112">
                    <papertitle>NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and Repulsive UDF</papertitle>
                  </a>
                  <br>
                  Stefan Lionar, <strong>Xiangyu Xu<sup>&#x2709</sup></strong>, Min Lin, Gim Hee Lee
                  <br>
                  <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023
                  <br>
                  <a href="https://arxiv.org/abs/2307.09112">Paper</a>
                  |
                  <a href="https://numcc.github.io/">Project</a>
                  <p>We achieve new SOTA for single-view 3D reconstruction on CO3D.</p>
                </td>
              </tr>

              <!-- TOG23 Sewformer -->
              <tr onmouseout="tog23sewformer_stop()" onmouseover="tog23sewformer_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='tog23sewformer_image'><video  width=100% height=100% muted autoplay loop>
                      <source src="images/tog23sewformer_after.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                      </video></div>
                    <!-- <div class="two" id='tog23sewformer_image'>
                      <img src='images/tog23sewformer_after.mp4' width="160">
                    </div> -->
                    <img src='images/tog23sewformer_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function tog23sewformer_start() {
                      document.getElementById('tog23sewformer_image').style.opacity = "1";
                    }

                    function tog23sewformer_stop() {
                      document.getElementById('tog23sewformer_image').style.opacity = "0";
                    }
                    tog23sewformer_stop()
                  </script>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://sewformer.github.io/">
                    <papertitle>Towards Garment Sewing Pattern Reconstruction from a Single Image</papertitle>
                  </a>
                  <br>
                  Lijuan Liu*, <strong>Xiangyu Xu*</strong>, Zhijie Lin*, Jiabin Liang*, Shuicheng Yan
                  <br>
                  <em>ACM Transactions on Graphics (<strong>SIGGRAPH Asia</strong>)</em>, 2023
                  <br>
                  <a href="http://arxiv.org/abs/2311.04218">Paper</a>
                  |
                  <a href="https://sewformer.github.io/">Code</a>
                  |
                  <a href="https://www.newscientist.com/article/2404358-ai-can-figure-out-sewing-patterns-from-a-single-photo-of-clothing/">New Scientist</a>
                  <p>We present the first solution for sewing pattern reconstruction from a single image.</p>
                </td>
              </tr>

              <!-- ICCV23 STPrivacy -->
              <tr>
                <td style="padding:20px;width:10%;vertical-align:middle">
                  <div>
                    <img src='images/iccv23stprivacy.png' width="180">
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://arxiv.org/abs/2301.03046">
                    <papertitle>STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition</papertitle>
                  </a>
                  <br>
                  Ming Li, <strong>Xiangyu Xu</strong>, Hehe Fan, Pan Zhou, Jun Liu, Jia-Wei Liu, Jiahe Li, Jussi Keppo,
                  Mike Zheng Shou, Shuicheng Yan
                  <br>
                  <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
                  <br>
                  <a href="https://arxiv.org/abs/2301.03046">Paper</a>
                  |
                  <a href="https://drive.google.com/file/d/1vLGdlpzom02TZnVOvqja-kUB-GxBmT95/view">Code</a>
                  <p>We explore privacy-preserving action recognition from a spatio-temporal perspective.</p>
                </td>
              </tr>

              <!-- TIP23 Cylin-Painting -->
              <tr>
                <td style="padding:20px;width:10%;vertical-align:middle">
                  <div>
                    <img src='images/tip23_cylin.png' width="160">
                  </div>
                </td>
                <td width="90%" valign="middle">
                  <a href="https://arxiv.org/abs/2204.08563">
                    <papertitle>Cylin-Painting: Seamless 360¬∞ Panoramic Image Outpainting and Beyond</papertitle>
                  </a>
                  <br>
                  Kang Liao, <strong>Xiangyu Xu</strong>, Chunyu Lin, Wenqi Ren, Yunchao Wei, Yao Zhao
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2023
                  <br>
                  <a href="https://arxiv.org/abs/2204.08563">Paper</a>
                  |
                  <a href="">Code</a>
                  <p>We propose a cylinder-style convolution for completing panoramic views.</p>
                </td>
              </tr>

              <!-- PAMI22 GLEAN -->
              <tr onmouseout="pami22glean_stop()" onmouseover="pami22glean_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='pami22glean_image'>
                      <img src='images/pami22glean_after.png' width="160">
                    </div>
                    <img src='images/pami22glean_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function pami22glean_start() {
                      document.getElementById('pami22glean_image').style.opacity = "1";
                    }

                    function pami22glean_stop() {
                      document.getElementById('pami22glean_image').style.opacity = "0";
                    }
                    pami22glean_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2207.14812.pdf">
                    <papertitle>GLEAN: Generative Latent Bank for Image Super-Resolution and Beyond</papertitle>
                  </a>
                  <br>
                  Kelvin C.K. Chan, <strong>Xiangyu Xu</strong>, Xintao Wang, Jinwei Gu, and Chen Change Loy
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/pdf/2207.14812.pdf">Paper</a>
                  |
                  <a href="https://github.com/open-mmlab/mmediting">Code</a>
                  <p>We develop a lighter version of GLEAN.</p>
                </td>
              </tr>

              <!-- ECCV22 gpnerf -->
              <tr onmouseout="gpnerf_stop()" onmouseover="gpnerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='gpnerf_image'>
                      <img src='images/eccv22gpnerf_after_119.gif' height="160">
                    </div>
                    <img src='images/eccv22gpnerf_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function gpnerf_start() {
                      document.getElementById('gpnerf_image').style.opacity = "1";
                    }

                    function gpnerf_stop() {
                      document.getElementById('gpnerf_image').style.opacity = "0";
                    }
                    gpnerf_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2112.04312">
                    <papertitle>Geometry-Guided Progressive NeRF for Generalizable and Efficient Neural Human Rendering
                    </papertitle>
                  </a>
                  <br>
                  Mingfei Chen, Jianfeng Zhang, <strong>Xiangyu Xu<sup>&#x2709</sup></strong>, Lijuan Liu, Yujun Cai,
                  Jiashi Feng, Shuicheng Yan
                  <br>
                  <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2112.04312">Paper</a>
                  |
                  <a href="https://github.com/sail-sg/GP-Nerf">Code</a>
                  <p>We present an SMPL-based NeRF for multi-view human synthesis, which is efficient and generalizable
                    to unseen subjects and sparse views.</p>
                </td>
              </tr>

              <!-- CVPR22 VFIT -->
              <tr onmouseout="cvpr22vfit_stop()" onmouseover="cvpr22vfit_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='cvpr22vfit_image'>
                      <img src='images/cvpr22vfit_after.gif' width="160">
                    </div>
                    <img src='images/cvpr22vfit_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function cvpr22vfit_start() {
                      document.getElementById('cvpr22vfit_image').style.opacity = "1";
                    }

                    function cvpr22vfit_stop() {
                      document.getElementById('cvpr22vfit_image').style.opacity = "0";
                    }
                    cvpr22vfit_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2111.12704">
                    <papertitle>Video Frame Interpolation Transformer</papertitle>
                  </a>
                  <br>
                  Zhihao Shi*, <strong>Xiangyu Xu*<sup>&#x2709</sup></strong>, Xiaohong Liu, Jun Chen, Ming-Hsuan Yang
                  <br>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2111.13817">Paper</a>
                  |
                  <a href="https://github.com/zhshi0816/Video-Frame-Interpolation-Transformer">Code</a>
                  <p>We present the first Transformer architecture for video frame interpolation.</p>
                </td>
              </tr>

              <!-- CVPR22 Real -->
              <tr onmouseout="cvpr22real_stop()" onmouseover="cvpr22real_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='cvpr22real_image'>
                      <img src='images/cvpr22real_after.png' width="160">
                    </div>
                    <img src='images/cvpr22real_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cvpr22real_start() {
                      document.getElementById('cvpr22real_image').style.opacity = "1";
                    }

                    function cvpr22real_stop() {
                      document.getElementById('cvpr22real_image').style.opacity = "0";
                    }
                    cvpr22real_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2111.12704">
                    <papertitle>Investigating Tradeoffs in Real-World Video Super-Resolution</papertitle>
                  </a>
                  <br>
                  Kelvin C.K. Chan, Shangchen Zhou, <strong>Xiangyu Xu</strong>, and Chen Change Loy
                  <br>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2111.12704">Paper</a>
                  |
                  <a href="https://github.com/ckkelvinchan/RealBasicVSR">Code</a>
                  <p>Several useful techniques for real-world video super-resolution.</p>
                </td>
              </tr>

              <!-- CVPR22 basicvsr++ -->
              <tr onmouseout="cvpr22basic_stop()" onmouseover="cvpr22basic_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='cvpr22basic_image'>
                      <img src='images/cvpr22basic_after.png' width="160">
                    </div>
                    <img src='images/cvpr22basic_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cvpr22basic_start() {
                      document.getElementById('cvpr22basic_image').style.opacity = "1";
                    }

                    function cvpr22basic_stop() {
                      document.getElementById('cvpr22basic_image').style.opacity = "0";
                    }
                    cvpr22basic_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2104.13371">
                    <papertitle>BasicVSR++: Improving Video Super-Resolution with Enhanced Propagation and Alignment
                    </papertitle>
                  </a>
                  <br>
                  Kelvin C.K. Chan, Shangchen Zhou, <strong>Xiangyu Xu</strong>, and Chen Change Loy
                  <br>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2104.13371">Paper</a>
                  |
                  <a href="https://ckkelvinchan.github.io/projects/BasicVSR++/">Project</a>
                  <p>Winner algorithm for video enhancement challenges in NTIRE 2021.</p>
                </td>
              </tr>

              <!-- ICCV21 texformer -->
              <tr onmouseout="iccv21tex_stop()" onmouseover="iccv21tex_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='iccv21tex_image'>
                      <img src='images/iccv21tex_after.gif' height="160">
                    </div>
                    <img src='images/iccv21tex_before.png' height="160">
                  </div>
                  <script type="text/javascript">
                    function iccv21tex_start() {
                      document.getElementById('iccv21tex_image').style.opacity = "1";
                    }

                    function iccv21tex_stop() {
                      document.getElementById('iccv21tex_image').style.opacity = "0";
                    }
                    iccv21tex_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2109.02563">
                    <papertitle>3D Human Texture Estimation from a Single Image with Transformers</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Chen Change Loy
                  <br>
                  <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021 &nbsp <font
                    color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/2109.02563">Paper</a>
                  |
                  <a href="https://github.com/xuxy09/Texformer">Code</a>
                  |
                  <a href="https://www.mmlab-ntu.com/project/texformer/">Project</a>
                  <p>We present a Transformer for 3D human texture estimation from a single image.</p>
                </td>
              </tr>

              <!-- TPAMI21 RSC-Net -->
              <tr onmouseout="pami21rsc_stop()" onmouseover="pami21rsc_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='pami21rsc_image'>
                      <img src='images/pami21rsc_after.png' width="160">
                    </div>
                    <img src='images/pami21rsc_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function pami21rsc_start() {
                      document.getElementById('pami21rsc_image').style.opacity = "1";
                    }

                    function pami21rsc_stop() {
                      document.getElementById('pami21rsc_image').style.opacity = "0";
                    }
                    pami21rsc_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2103.06498">
                    <papertitle>3D Human Pose, Shape and Texture from Low-Resolution Images and Videos</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Hao Chen, Francesc Moreno-Noguer, Laszlo A. Jeni, and Fernando De la
                  Torre
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2021
                  <br>
                  <a href="https://arxiv.org/abs/2103.06498">Paper</a>
                  |
                  <a href="https://github.com/xuxy09/RSC-Net">Code</a>
                  <p>We extend RSC-Net to videos and propose a human texture estimation model.</p>
                </td>
              </tr>

              <!-- CVPR21 GLEAN -->
              <tr onmouseout="cvpr21glean_stop()" onmouseover="cvpr21glean_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='cvpr21glean_image'>
                      <img src='images/cvpr21glean_after.png' width="160">
                    </div>
                    <img src='images/cvpr21glean_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cvpr21glean_start() {
                      document.getElementById('cvpr21glean_image').style.opacity = "1";
                    }

                    function cvpr21glean_stop() {
                      document.getElementById('cvpr21glean_image').style.opacity = "0";
                    }
                    cvpr21glean_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2012.00739.pdf">
                    <papertitle>GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution</papertitle>
                  </a>
                  <br>
                  Kelvin C.K. Chan, Xintao Wang, <strong>Xiangyu Xu</strong>, Jinwei Gu, and Chen Change Loy
                  <br>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2021 &nbsp <font
                  color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://arxiv.org/pdf/2012.00739.pdf">Paper</a>
                  |
                  <a href="https://ckkelvinchan.github.io/projects/GLEAN/">Project</a>
                  <p>We use StyleGAN for image super-resolution.</p>
                </td>
              </tr>

              <!-- CHI21 SR -->
              <tr onmouseout="chi21sr_stop()" onmouseover="chi21sr_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='chi21sr_image'>
                      <img src='images/chi21sr_after.gif' width="160">
                    </div>
                    <img src='images/chi21sr_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function chi21sr_start() {
                      document.getElementById('chi21sr_image').style.opacity = "1";
                    }

                    function chi21sr_stop() {
                      document.getElementById('chi21sr_image').style.opacity = "0";
                    }
                    chi21sr_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://dl.acm.org/doi/pdf/10.1145/3411764.3445703">
                    <papertitle>Super-Resolution Capacitive Touchscreens</papertitle>
                  </a>
                  <br>
                  Sven Mayer, <strong>Xiangyu Xu</strong>, and Chris Harrison
                  <br>
                  <em>ACM Conference on Human Factors in Computing Systems (<strong>CHI</strong>)</em>, 2021
                  <br>
                  <a href="https://dl.acm.org/doi/pdf/10.1145/3411764.3445703">Paper</a>
                  |
                  <a href="https://www.youtube.com/watch?v=vyLD2CSOMCE">YouTube</a>
                  <p>For the first time, super-resolution is applied to human-computer interaction.</p>
                </td>
              </tr>

              <!-- TPAMI20 RawSR -->
              <tr onmouseout="pami20raw_stop()" onmouseover="pami20raw_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='pami20raw_image'>
                      <img src='images/pami20raw_after.png' width="160">
                    </div>
                    <img src='images/pami20raw_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function pami20raw_start() {
                      document.getElementById('pami20raw_image').style.opacity = "1";
                    }

                    function pami20raw_stop() {
                      document.getElementById('pami20raw_image').style.opacity = "0";
                    }
                    pami20raw_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2102.01579.pdf">
                    <papertitle>Exploiting Raw Images for Real-Scene Super-Resolution</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Yongrui Ma, Wenxiu Sun, and Ming-Hsuan Yang
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2020
                  <br>
                  <a href="https://arxiv.org/pdf/2102.01579.pdf">Paper</a>
                  |
                  <a href="https://sites.google.com/view/xiangyuxu/rawsr_pami">Project</a>
                  |
                  <a href="https://github.com/xuxy09/RawSR">Code</a>
                  <p>We improve the RawSR architecture and extend it to image dehazing and depth upsampling.</p>
                </td>
              </tr>

              <!-- ECCV20 RSC-Net -->
              <tr onmouseout="eccv20rsc_stop()" onmouseover="eccv20rsc_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='eccv20rsc_image'>
                      <img src='images/eccv20rsc_after.png' width="160">
                    </div>
                    <img src='images/eccv20rsc_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function eccv20rsc_start() {
                      document.getElementById('eccv20rsc_image').style.opacity = "1";
                    }

                    function eccv20rsc_stop() {
                      document.getElementById('eccv20rsc_image').style.opacity = "0";
                    }
                    eccv20rsc_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2007.13666">
                    <papertitle>3D Human Shape and Pose from a Single Low-Resolution Image with Self-Supervised Learning
                    </papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Hao Chen, Francesc Moreno-Noguer, Laszlo A. Jeni, and Fernando De la
                  Torre
                  <br>
                  <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2007.13666">Paper</a>
                  |
                  <a href="https://sites.google.com/view/xiangyuxu/3d_eccv20">Project</a>
                  |
                  <a href="https://github.com/xuxy09/RSC-Net">Code</a>
                  <p>We propose a new algorithm for 3D human shape and pose estimation that is robust to low-resolution
                    input.</p>
                </td>
              </tr>

              <!-- TIP20 denoise -->
              <tr onmouseout="tip20denoise_stop()" onmouseover="tip20denoise_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='tip20denoise_image'>
                      <img src='images/tip20denoise_after2.png' width="160">
                    </div>
                    <img src='images/tip20denoise_before2.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function tip20denoise_start() {
                      document.getElementById('tip20denoise_image').style.opacity = "1";
                    }

                    function tip20denoise_stop() {
                      document.getElementById('tip20denoise_image').style.opacity = "0";
                    }
                    tip20denoise_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2101.10760">
                    <papertitle>Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and Video Denoising
                    </papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Muchen Li, Wenxiu Sun, and Ming-Hsuan Yang
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2101.10760">Paper</a>
                  |
                  <a href="https://github.com/jojo23333/STPAN">Code</a>
                  <p>We propose spatio-temporal deformable convolution kernels for image and video denoising.</p>
                </td>
              </tr>

              <!-- ICML20 FWM -->
              <tr onmouseout="icml20fwm_stop()" onmouseover="icml20fwm_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='icml20fwm_image'>
                      <img src='images/icml20fwm_after.png' width="160">
                    </div>
                    <img src='images/icml20fwm_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function icml20fwm_start() {
                      document.getElementById('icml20fwm_image').style.opacity = "1";
                    }

                    function icml20fwm_stop() {
                      document.getElementById('icml20fwm_image').style.opacity = "0";
                    }
                    icml20fwm_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="http://proceedings.mlr.press/v119/xu20f/xu20f.pdf">
                    <papertitle>Learning Factorized Weight Matrix for Joint Filtering</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Yongrui Ma, Wenxiu Sun
                  <br>
                  <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020 &nbsp <font
                  color="red"><strong>(Long Talk)</strong></font>
                  <br>
                  <a href="http://proceedings.mlr.press/v119/xu20f/xu20f.pdf">Paper</a>
                  |
                  <a href="https://github.com/xuxy09/FWM_ICML20">Project</a>
                  <p>We propose deep Robust PCA for joint image filtering.</p>
                </td>
              </tr>

              <!-- NIPS19 QVI -->
              <tr onmouseout="nips19qvi_stop()" onmouseover="nips19qvi_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='nips19qvi_image'>
                      <img src='images/nips19qvi_after.gif' width="160">
                    </div>
                    <img src='images/nips19qvi_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function nips19qvi_start() {
                      document.getElementById('nips19qvi_image').style.opacity = "1";
                    }

                    function nips19qvi_stop() {
                      document.getElementById('nips19qvi_image').style.opacity = "0";
                    }
                    nips19qvi_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/1911.00627">
                    <papertitle>Quadratic Video Interpolation</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu*</strong>, Siyao Li*, Wenxiu Sun, Qian Yin, and Ming-Hsuan Yang
                  <br>
                  <em>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2019 &nbsp
                  <font color="red"><strong>(Spotlight)</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/1911.00627">Paper</a>
                  |
                  <a href="https://github.com/xuxy09/QVI">Code</a>
                  <p>We present the first nonlinear motion model for image interpolation. The method won the Champion of
                    AIM 2019 video interpolation challenge.</p>
                </td>
              </tr>

              <!-- CVPR19 RawSR -->
              <tr onmouseout="cvpr19raw_stop()" onmouseover="cvpr19raw_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='cvpr19raw_image'>
                      <img src='images/cvpr19raw_after.png' width="160">
                    </div>
                    <img src='images/cvpr19raw_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cvpr19raw_start() {
                      document.getElementById('cvpr19raw_image').style.opacity = "1";
                    }

                    function cvpr19raw_stop() {
                      document.getElementById('cvpr19raw_image').style.opacity = "0";
                    }
                    cvpr19raw_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/1905.12156">
                    <papertitle>Towards Real Scene Super-Resolution with Raw Images</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Yongrui Ma, Wenxiu Sun
                  <br>
                  <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2019
                  <br>
                  <a href="https://arxiv.org/abs/1905.12156">Paper</a>
                  |
                  <a href="https://github.com/xuxy09/RawSR">Code</a>
                  <p>We present the first neural network for raw image based super-resolution. It works very well on
                    real-world input.</p>
                </td>
              </tr>

              <!-- TIP19 low light -->
              <tr onmouseout="tip19low_stop()" onmouseover="tip19low_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='tip19low_image'>
                      <img src='images/tip19low_after.png' width="160">
                    </div>
                    <img src='images/tip19low_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function tip19low_start() {
                      document.getElementById('tip19low_image').style.opacity = "1";
                    }

                    function tip19low_stop() {
                      document.getElementById('tip19low_image').style.opacity = "0";
                    }
                    tip19low_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://ieeexplore.ieee.org/document/8692732">
                    <papertitle>Low-Light Image Enhancement via a Deep Hybrid Network</papertitle>
                  </a>
                  <br>
                  Wenqi Ren, Sifei Liu, Lin Ma, Qianqian Xu, <strong>Xiangyu Xu</strong>, Xiaochun Cao, Junping Du,
                  Ming-Hsuan Yang
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2019
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/8692732">Paper</a>
                  <p>We present a hybrid structure of CNN and RNN for low-light image enhancement.</p>
                </td>
              </tr>

              <!-- ECCV18 rendering -->
              <tr onmouseout="eccv18render_stop()" onmouseover="eccv18render_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="center">
                    <div class="two" id='eccv18render_image'>
                      <img src='images/eccv18dof_after.png' width="140">
                    </div>
                    <img src='images/eccv18dof_before.png' width="140">
                  </div>
                  <script type="text/javascript">
                    function eccv18render_start() {
                      document.getElementById('eccv18render_image').style.opacity = "1";
                    }

                    function eccv18render_stop() {
                      document.getElementById('eccv18render_image').style.opacity = "0";
                    }
                    eccv18render_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <a
                    href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Xiangyu_Xu_Rendering_Portraitures_from_ECCV_2018_paper.pdf">
                    <papertitle>Rendering Portraitures from Monocular Camera and Beyond</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Deqing Sun, Sifei Liu, Wenqi Ren, Yu-Jin Zhang, Ming-Hsuan Yang, Jian Sun
                  <br>
                  <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018
                  <br>
                  <a
                    href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Xiangyu_Xu_Rendering_Portraitures_from_ECCV_2018_paper.pdf">Paper</a>
                  <p>We present a CRF-based pipeline and a deep neural filter for rendering shallow depth-of-field
                    effect with monocular camera.</p>
                </td>
              </tr>

              <!-- ECCV18 monocular depth -->
              <tr onmouseout="eccv18mono_stop()" onmouseover="eccv18mono_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='eccv18mono_image'>
                      <img src='images/eccv18mono_after.png' width="160">
                    </div>
                    <img src='images/eccv18mono_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function eccv18mono_start() {
                      document.getElementById('eccv18mono_image').style.opacity = "1";
                    }

                    function eccv18mono_stop() {
                      document.getElementById('eccv18mono_image').style.opacity = "0";
                    }
                    eccv18mono_stop()
                  </script>
                </td>
                <td width="75%" valign="middle">
                  <br />
                  <a
                    href="https://openaccess.thecvf.com/content_ECCV_2018/papers/YuKang_Gan_Monocular_Depth_Estimation_ECCV_2018_paper.pdf">
                    <papertitle>Monocular Depth Estimation with Affinity, Vertical Pooling and Label Enhancement
                    </papertitle>
                  </a>
                  <br>
                  Yukang Gan*, <strong>Xiangyu Xu</strong>*, Wenxiu Sun, Liang Lin
                  <br>
                  <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018
                  <br>
                  <a
                    href="https://openaccess.thecvf.com/content_ECCV_2018/papers/YuKang_Gan_Monocular_Depth_Estimation_ECCV_2018_paper.pdf">Paper</a>
                  <p>We propose to incorporate relative features, i.e., affinity, for monocular depth estimation.</p>
                </td>
              </tr>

              <!-- TIP18 deblur -->
              <tr onmouseout="tip18deblur_stop()" onmouseover="tip18deblur_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='tip18deblur_image'>
                      <img src='images/tip18deblur_after.png' width="160">
                    </div>
                    <img src='images/tip18deblur_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function tip18deblur_start() {
                      document.getElementById('tip18deblur_image').style.opacity = "1";
                    }

                    function tip18deblur_stop() {
                      document.getElementById('tip18deblur_image').style.opacity = "0";
                    }
                    tip18deblur_stop()
                  </script>
                </td>
                <td style="width:75%;vertical-align:middle">
                  <a href="papers/tip18_deblur.pdf">
                    <papertitle>Motion Blur Kernel Estimation via Deep Learning</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Jinshan Pan, Yu-Jin Zhang, Ming-Hsuan Yang
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2018
                  <br>
                  <a href="papers/tip18_deblur.pdf">Paper</a>
                  |
                  <a href="https://sites.google.com/view/xiangyuxu/deepedge_tip">Project</a>
                  <p>We present a deep neural network to extract salient edges for blind image deblurring.</p>
                </td>
              </tr>

              <!-- TIP18 dehaze -->
              <tr onmouseout="tip18dehaze_stop()" onmouseover="tip18dehaze_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div>
                    <div class="two" id='tip18dehaze_image'>
                      <img src='images/tip18dehaze_after.png' width="160">
                    </div>
                    <img src='images/tip18dehaze_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function tip18dehaze_start() {
                      document.getElementById('tip18dehaze_image').style.opacity = "1";
                    }

                    function tip18dehaze_stop() {
                      document.getElementById('tip18dehaze_image').style.opacity = "0";
                    }
                    tip18dehaze_stop()
                  </script>
                </td>
                <td style="width:75%;vertical-align:middle">
                  <a href="http://forestlinma.com/welcome_files/Wenqi_Ren_Deep_Video_Dehazing_TIP_2019.pdf">
                    <papertitle>Deep Video Dehazing with Semantic Segmentation</papertitle>
                  </a>
                  <br>
                  Wenqi Ren*, Jingang Zhang*, <strong>Xiangyu Xu</strong>*, Lin Ma, Xiaochun Cao, Gaofeng Meng, Wei Liu
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2018
                  <br>
                  <a href="http://forestlinma.com/welcome_files/Wenqi_Ren_Deep_Video_Dehazing_TIP_2019.pdf">Paper</a>
                  <p>We exploit a neural network to perform haze removal for videos.</p>
                </td>
              </tr>

              <!-- ICCV17 -->
              <tr onmouseout="iccv17scgan_stop()" onmouseover="iccv17scgan_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='iccv17scgan_image'>
                      <img src='images/iccv17scgan_after.png' width="160">
                    </div>
                    <img src='images/iccv17scgan_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function iccv17scgan_start() {
                      document.getElementById('iccv17scgan_image').style.opacity = "1";
                    }

                    function iccv17scgan_stop() {
                      document.getElementById('iccv17scgan_image').style.opacity = "0";
                    }
                    iccv17scgan_stop()
                  </script>
                </td>
                <td style="width:75%;vertical-align:middle">
                  <a href="https://faculty.ucmerced.edu/mhyang/papers/iccv2017_gan_super_deblur.pdf">
                    <papertitle>Learning to Super-Resolve Blurry Face and Text Images</papertitle>
                  </a>
                  <br>
                  <strong>Xiangyu Xu</strong>, Deqing Sun, Jinshan Pan, Yu-Jin Zhang, Hanspeter Pfister, Ming-Hsuan Yang
                  <br>
                  <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2017
                  <br>
                  <a href="https://faculty.ucmerced.edu/mhyang/papers/iccv2017_gan_super_deblur.pdf">Paper</a>
                  |
                  <a href="https://sites.google.com/view/xiangyuxu/deblursr_iccv17">Project</a>
                  <p>We present the first deep neural network for blind image super-resolution.</p>
                </td>
              </tr>

            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Professional Services</heading>
                  <p>
                    Area Chair: CVPR 2023, BMVC 2023, CVPR 2024, ICLR 2024, ECCV 2024, BMVC 2024, NeurIPS 2024
                    <br>
                    Session Chair: SIGGRAPH Asia 2023
                    <br>
                    Senior Program Committee: IJCAI 2021, AAAI 2023, AAAI 2024
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Students/Interns</heading>
                  <p>
                    <a href="https://sg.linkedin.com/in/stefan-putra-lionar">Stefan Lionar</a>, PhD (Sea AI Lab and NUS, 2023-2024)
                    <br>
                    <a href="https://ming1993li.github.io/">Ming Li</a>, Intern (Sea AI Lab, 2023)
                    <br>
                    <a href="https://github.com/Hhhhhhao">Hao Chen</a>, Master (CMU, 2019-2020), Now: PhD at CMU
                    <br>
                    <a href="https://jojoml.github.io/">Muchen Li</a>, Intern (SenseTime, 2018-2019), Now: PhD at UBC
                    <br>
                    <a href="https://scholar.google.com/citations?user=JwQLEocAAAAJ&hl=en">Yongrui Ma</a>, Intern (SenseTime, 2018-2019), Now: PhD at CUHK
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="30%" align="center" border="0" cellpadding="20">
            <tbody>

              <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=5T1sl0e94RWwdrLSEZTU3o1x6Bal583UadvbPPety1o"></script> -->
              <script type='text/javascript' id='clustrmaps'
                src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=5T1sl0e94RWwdrLSEZTU3o1x6Bal583UadvbPPety1o&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Website template from <a href="https://github.com/jonbarron/jonbarron_website">here</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>